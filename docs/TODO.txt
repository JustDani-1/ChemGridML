
- get final performance metrics RRMSE and AUROC for best hyperparams
    - compare performance with and without early stopping on final model
    - compare performance with and without patience as a tunable hyperparam
- add a single parameter for different preset fp x model x data as well as hyperparams space options
- get myriad pipeline working, run and evaluate first job
- function to generate benchmark just from the study



Presentation for Mark:
- present the papers
- quickly show MoleculeNet
- ask him in which direction the project should go? 
- molecular target or property prediction?
- go nuts with the featurizations or with the model types?
- WHAT IS THE DIRECTION OR QUESTION I AM TRYING TO ANSWER?
- use data and models like in Mayr but with the diversity of descriptors from the others?
- More diverse architectures: FNN, RNN, KNN, NB, SVM, RF, ...
-> would result in A LOT of models/computation


Follow-up:
- focus on combination of representation x model x dataset
- property prediction, not target prediction
- try to use curated datasets at first and then maybe try to use ChEMBL-extracted datasets, compare performance
    - compare performances over small, medium and large datasets
- features -> models -> datasets


Methods:
- We want a vectorization of all features
- Graphs:
    - test just plain GCN combined with other architectures
    - graphical autoencoder with other architectures, 
    - extract embedding from traditional GCN, combine with other architectures




