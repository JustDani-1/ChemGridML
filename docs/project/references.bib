@article{baptistaEvaluatingMolecularRepresentations,
  title = {Evaluating Molecular Representations in Machine Learning Models for Drug Response Prediction and Interpretability},
  author = {Baptista, Delora and Correia, João and Pereira, Bruno and Rocha, Miguel},
  journaltitle = {Journal of Integrative Bioinformatics},
  shortjournal = {J Integr Bioinform},
  volume = {19},
  number = {3},
  eprint = {36017668},
  eprinttype = {pubmed},
  pages = {20220006},
  issn = {1613-4516},
  doi = {10.1515/jib-2022-0006},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9521826/},
  urldate = {2025-08-19},
  abstract = {Machine learning (ML) is increasingly being used to guide drug discovery processes. When applying ML approaches to chemical datasets, molecular descriptors and fingerprints are typically used to represent compounds as numerical vectors. However, in recent years, end-to-end deep learning (DL) methods that can learn feature representations directly from line notations or molecular graphs have been proposed as alternatives to using precomputed features. This study set out to investigate which compound representation methods are the most suitable for drug sensitivity prediction in cancer cell lines. Twelve different representations were benchmarked on 5 compound screening datasets, using DeepMol, a new chemoinformatics package developed by our research group, to perform these analyses. The results of this study show that the predictive performance of end-to-end DL models is comparable to, and at times surpasses, that of models trained on molecular fingerprints, even when less training data is available. This study also found that combining several compound representation methods into an ensemble can improve performance. Finally, we show that a post hoc feature attribution method can boost the explainability of the DL models.},
  pmcid = {PMC9521826},
  file = {/Users/daniel/Zotero/storage/IHPQXZ5A/Baptista et al. - Evaluating molecular representations in machine learning models for drug response prediction and int.pdf}
}

@article{dengSystematicStudyKey2023,
  title = {A Systematic Study of Key Elements Underlying Molecular Property Prediction},
  author = {Deng, Jianyuan and Yang, Zhibo and Wang, Hehe and Ojima, Iwao and Samaras, Dimitris and Wang, Fusheng},
  date = {2023-10-13},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {6395},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-41948-6},
  url = {https://www.nature.com/articles/s41467-023-41948-6},
  urldate = {2025-08-21},
  abstract = {Artificial intelligence (AI) has been widely applied in drug discovery with a major task as molecular property prediction. Despite booming techniques in molecular representation learning, key elements underlying molecular property prediction remain largely unexplored, which impedes further advancements in this field. Herein, we conduct an extensive evaluation of representative models using various representations on the MoleculeNet datasets, a suite of opioids-related datasets and two additional activity datasets from the literature. To investigate the predictive power in low-data and high-data space, a series of descriptors datasets of varying sizes are also assembled to evaluate the models. In total, we have trained 62,820 models, including 50,220 models on fixed representations, 4200 models on SMILES sequences and 8400 models on molecular graphs. Based on extensive experimentation and rigorous comparison, we show that representation learning models exhibit limited performance in molecular property prediction in most datasets. Besides, multiple key elements underlying molecular property prediction can affect the evaluation results. Furthermore, we show that activity cliffs can significantly impact model prediction. Finally, we explore into potential causes why representation learning models can fail and show that dataset size is essential for representation learning models to excel.},
  langid = {english},
  keywords = {Cheminformatics,Machine learning},
  file = {/Users/daniel/Zotero/storage/8KCDTAQH/Deng et al. - 2023 - A systematic study of key elements underlying molecular property prediction.pdf}
}

@article{kamuntaviciusBenchmarkingMLADMET2025,
  title = {Benchmarking {{ML}} in {{ADMET}} Predictions: The Practical Impact of Feature Representations in Ligand-Based Models},
  shorttitle = {Benchmarking {{ML}} in {{ADMET}} Predictions},
  author = {Kamuntavičius, Gintautas and Paquet, Tanya and Bastas, Orestis and Šalkauskas, Dainius and Prat, Alvaro and Aty, Hisham Abdel and Pabrinkis, Aurimas and Norvaišas, Povilas and Tal, Roy},
  date = {2025-07-21},
  journaltitle = {Journal of Cheminformatics},
  shortjournal = {Journal of Cheminformatics},
  volume = {17},
  number = {1},
  pages = {108},
  issn = {1758-2946},
  doi = {10.1186/s13321-025-01041-0},
  url = {https://doi.org/10.1186/s13321-025-01041-0},
  urldate = {2025-08-21},
  abstract = {This study, focusing on predicting Absorption, Distribution, Metabolism, Excretion, and Toxicology (ADMET) properties, addresses the key challenges of ML models trained using ligand-based representations. We propose a structured approach to data feature selection, taking a step beyond the conventional practice of combining different representations without systematic reasoning. Additionally, we enhance model evaluation methods by integrating cross-validation with statistical hypothesis testing, adding a layer of reliability to the model assessments. Our final evaluations include a practical scenario, where models trained on one source of data are evaluated on a different one. This approach aims to bolster the reliability of ADMET predictions, providing more dependable and informative model evaluations.},
  file = {/Users/daniel/Zotero/storage/MU56V3GT/Kamuntavičius et al. - 2025 - Benchmarking ML in ADMET predictions the practical impact of feature representations in ligand-base.pdf;/Users/daniel/Zotero/storage/V5XYLD8Q/s13321-025-01041-0.html}
}

@article{mayrLargescaleComparisonMachine2018,
  title = {Large-Scale Comparison of Machine Learning Methods for Drug Target Prediction on {{ChEMBL}}},
  author = {Mayr, Andreas and Klambauer, Günter and Unterthiner, Thomas and Steijaert, Marvin and Wegner, Jörg K. and Ceulemans, Hugo and Clevert, Djork-Arné and Hochreiter, Sepp},
  date = {2018-06-20},
  journaltitle = {Chemical Science},
  shortjournal = {Chem. Sci.},
  volume = {9},
  number = {24},
  pages = {5441--5451},
  publisher = {The Royal Society of Chemistry},
  issn = {2041-6539},
  doi = {10.1039/C8SC00148K},
  url = {https://pubs.rsc.org/en/content/articlelanding/2018/sc/c8sc00148k},
  urldate = {2025-08-19},
  abstract = {Deep learning is currently the most successful machine learning technique in a wide range of application areas and has recently been applied successfully in drug discovery research to predict potential drug targets and to screen for active molecules. However, due to (1) the lack of large-scale studies, (2) the compound series bias that is characteristic of drug discovery datasets and (3) the hyperparameter selection bias that comes with the high number of potential deep learning architectures, it remains unclear whether deep learning can indeed outperform existing computational methods in drug discovery tasks. We therefore assessed the performance of several deep learning methods on a large-scale drug discovery dataset and compared the results with those of other machine learning and target prediction methods. To avoid potential biases from hyperparameter selection or compound series, we used a nested cluster-cross-validation strategy. We found (1) that deep learning methods significantly outperform all competing methods and (2) that the predictive performance of deep learning is in many cases comparable to that of tests performed in wet labs (i.e., in vitro assays).},
  langid = {english},
  file = {/Users/daniel/Zotero/storage/JU2GBBCW/Mayr et al. - 2018 - Large-scale comparison of machine learning methods for drug target prediction on ChEMBL.pdf;/Users/daniel/Zotero/storage/PUKCF997/Mayr et al. - 2018 - Large-scale comparison of machine learning methods for drug target prediction on ChEMBL.pdf}
}

@article{nichollsConfidenceLimitsError2016,
  title = {Confidence Limits, Error Bars and Method Comparison in Molecular Modeling. {{Part}} 2: Comparing Methods},
  shorttitle = {Confidence Limits, Error Bars and Method Comparison in Molecular Modeling. {{Part}} 2},
  author = {Nicholls, A.},
  date = {2016-02-01},
  journaltitle = {Journal of Computer-Aided Molecular Design},
  shortjournal = {J Comput Aided Mol Des},
  volume = {30},
  number = {2},
  pages = {103--126},
  issn = {1573-4951},
  doi = {10.1007/s10822-016-9904-5},
  url = {https://doi.org/10.1007/s10822-016-9904-5},
  urldate = {2025-09-05},
  abstract = {The calculation of error bars for quantities of interest in computational chemistry comes in two forms: (1) Determining the confidence of a prediction, for instance of the property of a molecule; (2) Assessing uncertainty in measuring the difference between properties, for instance between performance metrics of two or more computational approaches. While a former paper in this series concentrated on the first of these, this second paper focuses on comparison, i.e. how do we calculate differences in methods in an accurate and statistically valid manner. Described within are classical statistical approaches for comparing widely used metrics such as enrichment, area under the curve and Pearson’s product-moment coefficient, as well as generic measures. These are considered of over single and multiple sets of data and for two or more methods that evince either independent or correlated behavior. General issues concerning significance testing and confidence limits from a Bayesian perspective are discussed, along with size-of-effect aspects of evaluation.},
  langid = {english},
  keywords = {Bayes,Computational methods,Confidence intervals,Correlation,Error bars,Evaluations,Significance,Statistics},
  file = {/Users/daniel/Zotero/storage/FYXTDHJG/Nicholls - 2016 - Confidence limits, error bars and method comparison in molecular modeling. Part 2 comparing methods.pdf}
}

@online{rongSelfSupervisedGraphTransformer2020,
  title = {Self-{{Supervised Graph Transformer}} on {{Large-Scale Molecular Data}}},
  author = {Rong, Yu and Bian, Yatao and Xu, Tingyang and Xie, Weiyang and Wei, Ying and Huang, Wenbing and Huang, Junzhou},
  date = {2020-10-29},
  eprint = {2007.02835},
  eprinttype = {arXiv},
  eprintclass = {q-bio},
  doi = {10.48550/arXiv.2007.02835},
  url = {http://arxiv.org/abs/2007.02835},
  urldate = {2025-08-27},
  abstract = {How to obtain informative representations of molecules is a crucial prerequisite in AI-driven drug design and discovery. Recent researches abstract molecules as graphs and employ Graph Neural Networks (GNNs) for molecular representation learning. Nevertheless, two issues impede the usage of GNNs in real scenarios: (1) insufficient labeled molecules for supervised training; (2) poor generalization capability to new-synthesized molecules. To address them both, we propose a novel framework, GROVER, which stands for Graph Representation frOm self-superVised mEssage passing tRansformer. With carefully designed self-supervised tasks in node-, edge- and graph-level, GROVER can learn rich structural and semantic information of molecules from enormous unlabelled molecular data. Rather, to encode such complex information, GROVER integrates Message Passing Networks into the Transformer-style architecture to deliver a class of more expressive encoders of molecules. The flexibility of GROVER allows it to be trained efficiently on large-scale molecular dataset without requiring any supervision, thus being immunized to the two issues mentioned above. We pre-train GROVER with 100 million parameters on 10 million unlabelled molecules -- the biggest GNN and the largest training dataset in molecular representation learning. We then leverage the pre-trained GROVER for molecular property prediction followed by task-specific fine-tuning, where we observe a huge improvement (more than 6\% on average) from current state-of-the-art methods on 11 challenging benchmarks. The insights we gained are that well-designed self-supervision losses and largely-expressive pre-trained models enjoy the significant potential on performance boosting.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Biomolecules},
  file = {/Users/daniel/Zotero/storage/UBLLPYF5/Rong et al. - 2020 - Self-Supervised Graph Transformer on Large-Scale Molecular Data.pdf}
}

@article{stepisnikComprehensiveComparisonMolecular2021,
  title = {A Comprehensive Comparison of Molecular Feature Representations for Use in Predictive Modeling},
  author = {Stepišnik, Tomaž and Škrlj, Blaž and Wicker, Jörg and Kocev, Dragi},
  date = {2021-03},
  journaltitle = {Computers in Biology and Medicine},
  shortjournal = {Computers in Biology and Medicine},
  volume = {130},
  pages = {104197},
  issn = {00104825},
  doi = {10.1016/j.compbiomed.2020.104197},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S001048252030528X},
  urldate = {2025-08-19},
  abstract = {Machine learning methods are commonly used for predicting molecular properties to accelerate material and drug design. An important part of this process is deciding how to represent the molecules. Typically, machine learning methods expect examples represented by vectors of values, and many methods for calculating molecular feature representations have been proposed. In this paper, we perform a comprehensive comparison of different molecular features, including traditional methods such as fingerprints and molecular descriptors, and recently proposed learnable representations based on neural networks. Feature representations are evaluated on 11 benchmark datasets, used for predicting properties and measures such as mutagenicity, melting points, activity, solubility, and IC50. Our experiments show that several molecular features work similarly well over all benchmark datasets. The ones that stand out most are Spectrophores, which give significantly worse performance than other features on most datasets. Molecular descriptors from the PaDEL library seem very well suited for predicting physical properties of molecules. Despite their simplicity, MACCS fingerprints performed very well overall. The results show that learnable representations achieve competitive performance compared to expert based representations. However, task-specific representations (graph convolutions and Weave methods) rarely offer any benefits, even though they are computationally more demanding. Lastly, combining different molecular feature representations typically does not give a noticeable improvement in performance compared to individual feature representations.},
  langid = {english},
  file = {/Users/daniel/Zotero/storage/RRAU7HN3/Stepišnik et al. - 2021 - A comprehensive comparison of molecular feature representations for use in predictive modeling.pdf}
}

@online{ThoughtsSplittingChemical,
  title = {Some {{Thoughts}} on {{Splitting Chemical Datasets}}},
  url = {https://practicalcheminformatics.blogspot.com/2024/11/some-thoughts-on-splitting-chemical.html},
  urldate = {2025-09-05},
  organization = {Some Thoughts on Splitting Chemical Datasets},
  file = {/Users/daniel/Zotero/storage/ZEBPBXRW/some-thoughts-on-splitting-chemical.html}
}

@online{WeNeedBetter,
  title = {We {{Need Better Benchmarks}} for {{Machine Learning}} in {{Drug Discovery}}},
  url = {https://practicalcheminformatics.blogspot.com/2023/08/we-need-better-benchmarks-for-machine.html},
  urldate = {2025-09-05},
  organization = {We Need Better Benchmarks for Machine Learning in Drug Discovery},
  file = {/Users/daniel/Zotero/storage/ZM9KKUJY/we-need-better-benchmarks-for-machine.html}
}
